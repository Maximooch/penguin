# Not exclusive to OpenAI
# Check LiteLLM documentation to see how to use other providers
# https://docs.litellm.ai/docs/providers


model:
  default: "claude-3-5-sonnet-20241022"
  provider: "anthropic"

api:
  base_url: "https://api.anthropic.com/v1/messages"

model_configs:
  gpt-3.5-turbo:
    max_tokens: 4096
    temperature: 0.7
  gpt-4:
    max_tokens: 8192
    temperature: 0.7
  claude-3-opus-20240229:
    provider: "anthropic"
    # api_base: "https://api.anthropic.com/v1/messages"
    max_tokens: 4096
    temperature: 0.7

# Add other non-sensitive configuration options as needed


# https://api.openai.com/v1