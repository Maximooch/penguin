# Check LiteLLM documentation to see how to use other providers
# https://docs.litellm.ai/docs/providers

model:
  default: "claude-3-7-sonnet-20250219"
  provider: "anthropic"
  use_assistants_api: false # Add this line to toggle OpenAI Assistants API usage
  use_native_adapter: true  # Use direct Anthropic SDK instead of LiteLLM
  streaming_enabled: true   # Enable streaming support
  max_tokens: 8192
  temperature: 0.4
  context_window: 200000
  # temperature: 0.4


api:
  base_url: "https://api.anthropic.com/v1/messages"
  # If you're using ollama, set the base_url to the ollama server url, which is usually http://127.0.0.1:11434
  # It'll tell you if you do `ollama serve` in the terminal.

# /Users/maximusputnam/Documents/code/Penguin/workspace

# Workspace Configuration
workspace:
  path: "/Users/maximusputnam/Documents/code/Penguin/penguin_workspace"  # Default, can be overridden
  create_dirs:  # Subdirectories to create
    - conversations
    - memory_db
    - logs
    - notes
    - projects
    - context


diagnostics:
  enabled: false  # Global switch for diagnostics
  max_context_tokens: 200000
  log_to_file: false
  log_path: "logs/penguin.log"  # Optional, only used if log_to_file is true


# ------------------------------------------------------------------------------------------------
# Model Configs. You can ignore these unless you want to change the default model configs. 
# ------------------------------------------------------------------------------------------------
model_configs:
  gpt-4o: 
    max_tokens: 4096
    temperature: 0.4
    supports_vision: true
  gpt-3.5-turbo:
    max_tokens: 4096
    temperature: 0.7
  gpt-4:
    max_tokens: 8192
    temperature: 0.7
  claude-3-opus-20240229:
    provider: "anthropic"
    # api_base: "https://api.anthropic.com/v1/messages"
    max_tokens: 4096
    temperature: 0.7

# Add other non-sensitive configuration options as needed

# Tools:
# Toggle whatever tools you want to use, config.py then makes a list sending to core.py to inform what tools are available.
# 3rd party tools need to have a info.yml (txt, json, whatever type of text file) linked to that particular tool. So it could be loaded as a mini prompt.


# https://api.openai.com/v1