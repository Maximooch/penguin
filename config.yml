# I think this is redundant

workspace:
  path: "/tmp/penguin_workspace"

model:
  default: "gpt-4o-mini"
  provider: "openai"
  client_preference: "litellm"

model_configs:
  kimi-k2-0905:
    model: "moonshotai/kimi-k2-0905"
    provider: "openrouter"
    client_preference: "openrouter"
    max_tokens: 262000
    temperature: 0.5
    streaming_enabled: true

api:
  base_url: "https://api.openai.com/v1"

memory:
  enabled: false

performance:
  fast_startup: true
  profiling: true

diagnostics:
  enabled: false
